x <- seq(0,20, by = .001)
y <- dgamma(x, 2, .5)
ggplot() +
geom_line(aes(x = x, y = y)) +
labs(title = expression(paste("Prior Distribution of ", lambda_{2})))
x <- seq(0,20, by = .001)
y <- dgamma(x, 2, .5)
ggplot() +
geom_line(aes(x = x, y = y)) +
labs(title = expression(paste("Prior Distribution of ", lambda[2])))
x <- seq(0,20, by = .001)
y <- dgamma(x, 2, .5)
ggplot() +
geom_line(aes(x = x, y = y)) +
labs(title = expression(paste("Prior Distribution of ", lambda[2])))
expected <- 2/.5
variance <- 2/(.5^2)
sqrt(8)
2.8*3
gamma_2 <- 2 + 102
phi_2 <- .5 + 37
lower <- qgamma(.025, gamma_2, phi_2)
upper <- qgamma(.975, gamma_2, phi_2)
h_gamma_2 <- 2 + 185
h_phi_2 <- .5 + 41
sample1 <- rgamma(10000, c_gamma_2, c_phi_2)
c_gamma_2 <- 2 + 102
c_phi_2 <- .5 + 37
h_gamma_2 <- 2 + 185
h_phi_2 <- .5 + 41
sample1 <- rgamma(10000, c_gamma_2, c_phi_2)
sample2 <- rgamma(10000, h_gamma_2, h_phi_2)
difs <- sample2 - sample1
lower <- qgamma(.025, gamma_2, phi_2)
upper <- qgamma(.975, gamma_2, phi_2)
185/41
201/37
102/37
h_gamma_2 <- 2 + 185
h_phi_2 <- .5 + 41
sample1 <- rgamma(10000, c_gamma_2, c_phi_2)
sample2 <- rgamma(10000, h_gamma_2, h_phi_2)
difs <- sample2 - sample1
lower <- quantile(difs, .025)
upper <- quantile(difs, .975)
lower
upper
sigma2 <- .821
lambda <- 6
tau2 <- 10
data <- 1244
n <- 232
lambda.post <- ((tau2*data)+(sigma2*lambda))/((tau2*n)+sigma2)
tau2.post <- (sigma2*tau2)/((tau2*n)+sigma2)
lambda.post
data/n
sd(data)
var(data)
tau2.post
x <- seq(3,6, by = .001)
y <- dnorm(x, lambda.post, tau2.post)
ggplot() +
geom_line(aes(x = x, y = y)) +
labs(title = expression(paste("Posterior Distribution of ", lambda[W])))
x <- seq(5.2,5.5, by = .001)
y <- dnorm(x, lambda.post, tau2.post)
ggplot() +
geom_line(aes(x = x, y = y)) +
labs(title = expression(paste("Posterior Distribution of ", lambda[W])))
x <- seq(5.3,5.4, by = .001)
y <- dnorm(x, lambda.post, tau2.post)
ggplot() +
geom_line(aes(x = x, y = y)) +
labs(title = expression(paste("Posterior Distribution of ", lambda[W])))
x <- seq(5.3,5.4, by = .001)
y <- dnorm(x, lambda.post, tau2.post)
ggplot() +
geom_line(aes(x = x, y = y)) +
labs(title = expression(paste("Posterior Distribution of ", mu[W])))
x <- seq(5.3,5.4, by = .001)
y <- dnorm(x, lambda.post, tau2.post)
ggplot() +
geom_line(aes(x = x, y = y)) +
labs(title = expression(paste("Posterior Distribution of ", mu[F])))
lower <- qnorm(.025, lambda.post, tau2.post)
upper <- qnorm(.975, lambda.post, tau2.post)
?Seq
?seq\
?seq
mus <- rnorm(10000, lambda.post, tau2.post)
xs <- rnorm(1, mus, seq(sigma2, by = 10000))
mus <- rnorm(10000, lambda.post, tau2.post)
xs <- rnorm(1, mus, rep(10000, sigma2))
mus <- rnorm(10000, lambda.post, tau2.post)
xs <- rnorm(1, mus, rep(sigma2, 10000))
rep(sigma2, 10000)
mus
rnorm(1, mus, rep(sigma2, 10000))
mus <- rnorm(10000, lambda.post, tau2.post)
xs <- rnorm(10000, mus, rep(sigma2, 10000))
mus <- rnorm(10000, lambda.post, tau2.post)
xs <- rnorm(10000, mus, rep(sigma2, 10000))
lower <- quantile(xs, .025)
upper <- quantile(xs, .975)
lower
upper
new_lower <- exp(lower)
new_upper <- exp(upper)
exp(3.75)
new_lower
new_upper
sigma2 <- 1.51
lambda <- 6
tau2 <- 10
data <- 403
n <- 67
lambda.post <- ((tau2*data)+(sigma2*lambda))/((tau2*n)+sigma2)
tau2.post <- (sigma2*tau2)/((tau2*n)+sigma2)
mus <- rnorm(10000, lambda.post, tau2.post)
xs <- rnorm(10000, mus, rep(sigma2, 10000))
lower <- quantile(xs, .025)
upper <- quantile(xs, .975)
new_lower <- exp(lower)
new_upper <- exp(upper)
new_lower
new_upper
403/67
1244/232
mean(xs)
sigma2 <- .821
lambda <- 6
tau2 <- 10
data <- 1244
n <- 232
lambda.post <- ((tau2*data)+(sigma2*lambda))/((tau2*n)+sigma2)
tau2.post <- (sigma2*tau2)/((tau2*n)+sigma2)
mus <- rnorm(10000, lambda.post, tau2.post)
xs <- rnorm(10000, mus, rep(sigma2, 10000))
lower <- quantile(xs, .025)
upper <- quantile(xs, .975)
mean(xs)
alpha.post <- (3*35) + .65
beta.post <- 4.35 + 192
alpha.post <- (3*35) + .65
beta.post <- 4.35 + 192
lower <- (3/qbeta(.025, alpha.post, beta.post))-3
upper <- (3/qbeta(.975, alpha.post, beta.post))-3
lower
upper
alpha.post <- (3*35) + .65
beta.post <- 4.35 + 192
samp <- rbeta(10000, alpha.post, beta.post)
alpha.post <- (3*35) + .65
beta.post <- 4.35 + 192
samp <- rbeta(10000, alpha.post, beta.post)
lower <- quantile(samp, .025)
upper <- quantile(samp, .975)
lower
upper
3/lower
3/upper
alpha.post <- (3*35) + .65
beta.post <- 4.35 + 192
samp <- rbeta(10000, alpha.post, beta.post)
(3/lower-3)
lower <- quantile(samp, .025)
upper <- quantile(samp, .975)
real_lower <- (3/upper)-3
real_upper <- (3/lower)-3
real_lower
real_upper
3/.404-3
192/35
mus <- 3/samp-3
quantile(mus, .025)
quantile(mus, .975)
# create sequence of xs and ys
x <- seq(0,20, by = .001)
y <- dgamma(x, 2, .5)
ggplot() +
geom_line(aes(x = x, y = y)) +
labs(title = expression(paste("Prior Distribution of ", lambda[2])))
# find expected value and variance of prior
expected <- 2/.5
variance <- 2/(.5^2)
(9/6)-3-(1/2)
9-18-3
12*64
1/.4
1.4*2.5
3.5*2.5
2.5*2.5
8.75+6.25
ln1
ln(1)
log(1)
?rbinom
rbinom(1,1,.3)
rbinom(1,1,.3)
rbinom(1,1,.3)
rbinom(1,1,.3)
rbinom(1,1,.3)
rbinom(5,1,.3)
rbinom(5,2,.3)
setwd("~/Documents/Stat 348/ItemDemand")
library(tidyverse)
library(patchwork)
library(timetk)
library(vroom)
library(tidymodels)
## Read in Data
test <- vroom('test.csv')
train <- vroom('train.csv')
store1_item3 <- train1_3 <- train %>%
filter(store == 1 & item == 3)
store5_item7 <- train5_7 <- train %>%
filter(store == 5 & item == 7)
library(forecast)
library(modeltime)
arima_recipe <- recipe(sales~date, data = train) %>%
step_date(date, features = c("dow", "month", "year", "doy"))
arima_model <- arima_reg(seasonal_period=365,
non_seasonal_ar = 5,
non_seasonal_ma = 5,
seasonal_ar = 2,
seasonal_ma = 2,
non_seasonal_differences = 2,
seasonal_differences = 2) %>%
set_engine("auto_arima")
cv_split <- time_series_split(train5_7, assess = '3 months', cumulative  = TRUE)
arima_wf <- workflow() %>%
add_recipe(arima_recipe) %>%
add_model(arima_model) %>%
fit(data = training(cv_split))
cv_results <- modeltime_calibrate(arima_wf,
new_data = testing(cv_split))
# Visualize CV results
p1 <- cv_results %>%
modeltime_forecast(
new_data = testing(cv_split),
actual_data = train5_7) %>%
plot_modeltime_forecast(.interactive = TRUE)
## Evaluate the accuracy
cv_results %>%
modeltime_accuracy() %>%
table_modeltime_accuracy(
.interactive = FALSE
)
arima_fullfit <- cv_results %>%
modeltime_refit(data = train5_7)
arima_preds <- arima_fullfit %>%
modeltime_forecast(h = '3 months') %>%
rename(date = .index, sales = .value) %>%
select(date, sales) %>%
full_join(., y = test, by = 'date') %>%
select(id, sales)
p2 <- arima_fullfit %>%
modeltime_forecast(h = '2 years', actual_data = train5_7) %>%
plot_modeltime_forecast(.interactive = FALSE)
p2
library(prophet)
cv_split <- time_series_split(train1_3, assess = '3 months', cumulative  = TRUE)
prophet_model <- prophet_reg() %>%
set_engine(engine = "prophet") %>%
fit(sales~date, data = training(cv_split))
# Cross_validate to tune model
cv_results <- modeltime_calibrate(prophet_model,
new_data = testing(cv_split))
# Visualize CV results
p3 <- cv_results %>%
modeltime_forecast(
new_data = testing(cv_split),
actual_data = train1_3) %>%
plot_modeltime_forecast(.interactive = TRUE)
## Evaluate the accuracy
cv_results %>%
modeltime_accuracy() %>%
table_modeltime_accuracy(
.interactive = FALSE
)
prophet_fulfitt <- cv_results %>%
modeltime_refit(data = train1_3)
prophet_preds <- prophet_fulfitt %>%
modeltime_forecast(h = '3 months') %>%
rename(date = .index, sales = .value) %>%
select(date, sales) %>%
full_join(., y = test, by = 'date') %>%
select(id, sales)
p4 <- prophet_fulfitt %>%
modeltime_forecast(h = '2 year', actual_data = train5_7) %>%
plot_modeltime_forecast(.interactive = FALSE)
p4
arima_wf
tidy(arima_wf)
arima_wf %>% extract_fit_engine()
arima_recipe <- recipe(sales~date, data = train) #%>%
arima_model <- arima_reg(seasonal_period=365,
non_seasonal_ar = 5,
non_seasonal_ma = 5,
seasonal_ar = 2,
seasonal_ma = 2,
non_seasonal_differences = 2,
seasonal_differences = 2) %>%
set_engine("auto_arima")
cv_split <- time_series_split(train5_7, assess = '3 months', cumulative  = TRUE)
arima_wf <- workflow() %>%
add_recipe(arima_recipe) %>%
add_model(arima_model) %>%
fit(data = training(cv_split))
cv_results <- modeltime_calibrate(arima_wf,
new_data = testing(cv_split))
# Visualize CV results
p1 <- cv_results %>%
modeltime_forecast(
new_data = testing(cv_split),
actual_data = train5_7) %>%
plot_modeltime_forecast(.interactive = TRUE)
## Evaluate the accuracy
cv_results %>%
modeltime_accuracy() %>%
table_modeltime_accuracy(
.interactive = FALSE
)
arima_fullfit <- cv_results %>%
modeltime_refit(data = train5_7)
arima_preds <- arima_fullfit %>%
modeltime_forecast(h = '3 months') %>%
rename(date = .index, sales = .value) %>%
select(date, sales) %>%
full_join(., y = test, by = 'date') %>%
select(id, sales)
p2 <- arima_fullfit %>%
modeltime_forecast(h = '2 years', actual_data = train5_7) %>%
plot_modeltime_forecast(.interactive = FALSE)
p2
arima_wf
arima_recipe <- recipe(sales~date, data = train5_7) %>%
step_date(date, features = c("dow", "month", "year", "doy"))
arima_model <- arima_reg(seasonal_period=365,
non_seasonal_ar = 5,
non_seasonal_ma = 5,
seasonal_ar = 2,
seasonal_ma = 2,
non_seasonal_differences = 2,
seasonal_differences = 2) %>%
set_engine("auto_arima")
cv_split <- time_series_split(train5_7, assess = '3 months', cumulative  = TRUE)
arima_wf <- workflow() %>%
add_recipe(arima_recipe) %>%
add_model(arima_model) %>%
fit(data = training(cv_split))
arima_wf
arima_recipe <- recipe(sales~date, data = train5_7) %>%
step_date(date, features = c( "year", "doy"))
arima_model <- arima_reg(seasonal_period=365,
non_seasonal_ar = 5,
non_seasonal_ma = 5,
seasonal_ar = 2,
seasonal_ma = 2,
non_seasonal_differences = 2,
seasonal_differences = 2) %>%
set_engine("auto_arima")
cv_split <- time_series_split(train5_7, assess = '3 months', cumulative  = TRUE)
arima_wf <- workflow() %>%
add_recipe(arima_recipe) %>%
add_model(arima_model) %>%
fit(data = training(cv_split))
cv_results <- modeltime_calibrate(arima_wf,
new_data = testing(cv_split))
# Visualize CV results
p1 <- cv_results %>%
modeltime_forecast(
new_data = testing(cv_split),
actual_data = train5_7) %>%
plot_modeltime_forecast(.interactive = TRUE)
## Evaluate the accuracy
cv_results %>%
modeltime_accuracy() %>%
table_modeltime_accuracy(
.interactive = FALSE
)
arima_fullfit <- cv_results %>%
modeltime_refit(data = train5_7)
arima_preds <- arima_fullfit %>%
modeltime_forecast(h = '3 months') %>%
rename(date = .index, sales = .value) %>%
select(date, sales) %>%
full_join(., y = test, by = 'date') %>%
select(id, sales)
p2 <- arima_fullfit %>%
modeltime_forecast(h = '2 years', actual_data = train5_7) %>%
plot_modeltime_forecast(.interactive = FALSE)
p2
arima_wf
p1
# Visualize CV results
p1 <- cv_results %>%
modeltime_forecast(
h = '2 years',
new_data = testing(cv_split),
actual_data = train5_7) %>%
plot_modeltime_forecast(.interactive = TRUE)
p1
?modeltime_forecast
arima_recipe <- recipe(sales~date, data = train5_7) %>%
step_date(date, features = c("year", "doy", "dow", "month"))
arima_model <- arima_reg(seasonal_period=365,
non_seasonal_ar = 5,
non_seasonal_ma = 5,
seasonal_ar = 2,
seasonal_ma = 2,
non_seasonal_differences = 2,
seasonal_differences = 2) %>%
set_engine("auto_arima")
cv_split <- time_series_split(train5_7, assess = '3 months', cumulative  = TRUE)
arima_wf <- workflow() %>%
add_recipe(arima_recipe) %>%
add_model(arima_model) %>%
fit(data = training(cv_split))
cv_results <- modeltime_calibrate(arima_wf,
new_data = testing(cv_split))
# Visualize CV results
p1 <- cv_results %>%
modeltime_forecast(
new_data = testing(cv_split),
actual_data = train5_7) %>%
plot_modeltime_forecast(.interactive = TRUE)
p1
arima_recipe <- recipe(sales~date, data = train5_7) %>%
step_date(date, features = c("year", "doy", "month"))
arima_model <- arima_reg(seasonal_period=365,
non_seasonal_ar = 5,
non_seasonal_ma = 5,
seasonal_ar = 2,
seasonal_ma = 2,
non_seasonal_differences = 2,
seasonal_differences = 2) %>%
set_engine("auto_arima")
cv_split <- time_series_split(train5_7, assess = '3 months', cumulative  = TRUE)
arima_wf <- workflow() %>%
add_recipe(arima_recipe) %>%
add_model(arima_model) %>%
fit(data = training(cv_split))
cv_results <- modeltime_calibrate(arima_wf,
new_data = testing(cv_split))
# Visualize CV results
p1 <- cv_results %>%
modeltime_forecast(
new_data = testing(cv_split),
actual_data = train5_7) %>%
plot_modeltime_forecast(.interactive = TRUE)
p1
## Evaluate the accuracy
cv_results %>%
modeltime_accuracy() %>%
table_modeltime_accuracy(
.interactive = FALSE
)
arima_wf
arima_recipe <- recipe(sales~date, data = train5_7) %>%
step_date(date, features = c("year", "doy","dow", "month"))
arima_model <- arima_reg(seasonal_period=365,
non_seasonal_ar = 5,
non_seasonal_ma = 5,
seasonal_ar = 2,
seasonal_ma = 2,
non_seasonal_differences = 2,
seasonal_differences = 2) %>%
set_engine("auto_arima")
cv_split <- time_series_split(train5_7, assess = '3 months', cumulative  = TRUE)
arima_wf <- workflow() %>%
add_recipe(arima_recipe) %>%
add_model(arima_model) %>%
fit(data = training(cv_split))
cv_results <- modeltime_calibrate(arima_wf,
new_data = testing(cv_split))
# Visualize CV results
p1 <- cv_results %>%
modeltime_forecast(
new_data = testing(cv_split),
actual_data = train5_7) %>%
plot_modeltime_forecast(.interactive = TRUE)
## Evaluate the accuracy
cv_results %>%
modeltime_accuracy() %>%
table_modeltime_accuracy(
.interactive = FALSE
)
p4 <- prophet_fulfitt %>%
modeltime_forecast(h = '2 year', actual_data = train1_3) %>%
plot_modeltime_forecast(.interactive = FALSE)
p4
library(prophet)
cv_split <- time_series_split(train1_3, assess = '3 months', cumulative  = TRUE)
prophet_model <- prophet_reg() %>%
set_engine(engine = "prophet") %>%
fit(sales~date, data = training(cv_split))
# Cross_validate to tune model
cv_results <- modeltime_calibrate(prophet_model,
new_data = testing(cv_split))
# Visualize CV results
p3 <- cv_results %>%
modeltime_forecast(
new_data = testing(cv_split),
actual_data = train1_3) %>%
plot_modeltime_forecast(.interactive = TRUE)
## Evaluate the accuracy
cv_results %>%
modeltime_accuracy() %>%
table_modeltime_accuracy(
.interactive = FALSE
)
